{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Ernesto Rodr√≠guez\n",
    "# github.com/ernestorodg\n",
    "\n",
    "###############################################################################\n",
    "## Analyse Bezerra's dataset for intrusion detection using Decision Trees\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "###############################################################################\n",
    "## Define constants \n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Random state for reproducibility\n",
    "STATE = 0\n",
    "np.random.seed(10)\n",
    "# List of available attacks on the dataset\n",
    "\n",
    "\n",
    "# Especific to the repository \n",
    "DATASET_DIRECTORY = r'../datasets/Dataset-bezerra-IoT-20200528T203526Z-001/Dataset-IoT/'\n",
    "NETFLOW_DIRECTORY = r'NetFlow/'\n",
    "\n",
    "\n",
    "# There are different csv files on the Dataset, with different types of data:\n",
    "\n",
    "# Some meanings:\n",
    "# MC: Media Center\n",
    "# I: One hour of legitimate and malicious NetFlow data from profile.\n",
    "# L: One hour of legitimate NetFlow data from profile.\n",
    "\n",
    "MC = r'MC/'\n",
    "ST = r'ST/'\n",
    "SC = r'SC/'\n",
    "\n",
    "\n",
    "# MC_I_FIRST: Has infected data by Hajime, Aidra and BashLite botnets \n",
    "MC_I_FIRST = r'MC_I1.csv'\n",
    "\n",
    "# MC_I_SECOND: Has infected data from Mirai botnets\n",
    "MC_I_SECOND = r'MC_I2.csv'\n",
    "\n",
    "# MC_I_THIR: Has infected data from Mirai, Doflo, Tsunami and Wroba botnets\n",
    "MC_I_THIRD = r'MC_I3.csv'\n",
    "\n",
    "# MC_L: Has legitimate data, no infection\n",
    "MC_L = r'MC_L.csv'\n",
    "\n",
    "\n",
    "# Constants for ST\n",
    "ST_I_FIRST = r'ST_I1.csv'\n",
    "ST_I_SECOND = r'ST_I2.csv'\n",
    "ST_I_THIRD = r'ST_I3.csv'\n",
    "ST_L = r'ST_L.csv'\n",
    "\n",
    "# Constants for SC\n",
    "SC_I_FIRST = r'SC_I1.csv'\n",
    "SC_I_SECOND = r'SC_I2.csv'\n",
    "SC_I_THIRD = r'SC_I3.csv'\n",
    "SC_L = r'SC_L.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Load dataset\n",
    "###############################################################################\n",
    "\n",
    "# For MC data:\n",
    "df_mc_I_first = pd.read_csv (DATASET_DIRECTORY + MC + NETFLOW_DIRECTORY + MC_I_FIRST)\n",
    "df_mc_I_second = pd.read_csv (DATASET_DIRECTORY + MC + NETFLOW_DIRECTORY + MC_I_SECOND)\n",
    "df_mc_I_third = pd.read_csv (DATASET_DIRECTORY + MC + NETFLOW_DIRECTORY + MC_I_THIRD)\n",
    "\n",
    "# Add legitimate rows from MC_L\n",
    "legitimate_frame_mc = pd.read_csv (DATASET_DIRECTORY + MC + NETFLOW_DIRECTORY + MC_L)\n",
    "\n",
    "###################\n",
    "\n",
    "# For ST data:\n",
    "df_st_I_first = pd.read_csv (DATASET_DIRECTORY + ST + NETFLOW_DIRECTORY + ST_I_FIRST)\n",
    "df_st_I_second = pd.read_csv (DATASET_DIRECTORY + ST + NETFLOW_DIRECTORY + ST_I_SECOND)\n",
    "df_st_I_third = pd.read_csv (DATASET_DIRECTORY + ST + NETFLOW_DIRECTORY + ST_I_THIRD)\n",
    "\n",
    "# Add legitimate rows from SC_L\n",
    "legitimate_frame_st = pd.read_csv (DATASET_DIRECTORY + ST + NETFLOW_DIRECTORY + ST_L)\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "# For SC data:\n",
    "df_sc_I_first = pd.read_csv (DATASET_DIRECTORY + SC + NETFLOW_DIRECTORY + SC_I_FIRST)\n",
    "df_sc_I_second = pd.read_csv (DATASET_DIRECTORY + SC + NETFLOW_DIRECTORY + SC_I_SECOND)\n",
    "df_sc_I_third = pd.read_csv (DATASET_DIRECTORY + SC + NETFLOW_DIRECTORY + SC_I_THIRD)\n",
    "\n",
    "# Add legitimate rows from MC_L\n",
    "legitimate_frame_sc = pd.read_csv (DATASET_DIRECTORY + SC + NETFLOW_DIRECTORY + SC_L)\n",
    "\n",
    "dataframes_list = [df_mc_I_first,\n",
    "                df_mc_I_second,\n",
    "                df_mc_I_third,\n",
    "                legitimate_frame_mc,\n",
    "                df_st_I_first,\n",
    "                df_st_I_second,\n",
    "                df_st_I_third,\n",
    "                legitimate_frame_st,\n",
    "                df_sc_I_first,\n",
    "                df_sc_I_second,\n",
    "                df_sc_I_third,\n",
    "                legitimate_frame_sc]\n",
    "\n",
    "# Joining the differents DataFrames\n",
    "prev_df = pd.concat(dataframes_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Create artificial non-attacks samples\n",
    "###############################################################################\n",
    "\n",
    "# This may take time, grab a cup of coffee\n",
    "\n",
    "legitimate_frame = pd.concat([legitimate_frame_mc,legitimate_frame_st, legitimate_frame_sc])\n",
    "\n",
    "for index in range (0, prev_df.shape[0] // legitimate_frame.shape[0]):\n",
    "    prev_df = pd.concat([prev_df, legitimate_frame])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Modify the DataFrame\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Sample the dataset if necessary\n",
    "df = prev_df.sample (frac = 1, replace = True, random_state = 0)\n",
    "\n",
    "# We can see that this dataset has a temporal description.\n",
    "# So it is not a good idea to randomly remove rows\n",
    "\n",
    "# In this case we drop the index column, since pandas library creates an index\n",
    "# automatically. \n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "# Also drop columns that has no significant data\n",
    "df = df.drop(df.columns[14:], axis=1)\n",
    "\n",
    "# Initial and end time is not a good feature for svm model\n",
    "df = df.drop(['ts', 'te'], axis=1)\n",
    "\n",
    "# Trying another drops to see relation between features and results\n",
    "df = df.drop(['fwd', 'stos'], axis=1)\n",
    "# 'sp', 'dp', 'sa',  'da',  \n",
    "\n",
    "# Counting number of null data\n",
    "nanColumns = [i for i in df.columns if df [i].isnull ().any ()]\n",
    "\n",
    "# Remove NaN and inf values\n",
    "df.replace ('Infinity', np.nan, inplace = True) ## Or other text values\n",
    "df.replace (np.inf, np.nan, inplace = True) ## Remove infinity\n",
    "df.replace (np.nan, 0, inplace = True)\n",
    "\n",
    "\n",
    "# if (df.Label.value_counts()[1] < df.Label.value_counts()[0]):\n",
    "#     remove_n =  df.Label.value_counts()[0] - df.Label.value_counts()[1]  # Number of rows to be removed   \n",
    "#     print(remove_n)\n",
    "#     df_to_be_dropped = df[df.Label == 0]\n",
    "#     drop_indices = np.random.choice(df_to_be_dropped.index, remove_n, replace=False)\n",
    "#     df = df.drop(drop_indices)\n",
    "# else: \n",
    "#     remove_n =  df.Label.value_counts()[1] - df.Label.value_counts()[0]  # Number of rows to be removed   \n",
    "#     print(remove_n)\n",
    "#     df_to_be_dropped = df[df.Label == 1]\n",
    "#     drop_indices = np.random.choice(df_to_be_dropped.index, remove_n, replace=False)\n",
    "#     df = df.drop(drop_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-attacks:  1729705\n",
      "Number of attacks:  1717051\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Slice the dataframe (usually the last column is the target)\n",
    "###############################################################################\n",
    "\n",
    "X = pd.DataFrame(df.iloc [:, 1:])\n",
    "\n",
    "# Selecting other columns\n",
    "# X = pd.concat([X, df.iloc[:, 2]], axis=1)\n",
    "\n",
    "y = df.iloc [:, 0]\n",
    "print('Number of non-attacks: ', y.value_counts()[0])\n",
    "print('Number of attacks: ', y.value_counts()[1])\n",
    "\n",
    "# See Output, only available on jupyter-notebooks\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Split dataset into train and test sets if not using cross validation\n",
    "###############################################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 1/5,\n",
    "                                                     random_state = STATE)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Treat categorical data on train set\n",
    "####################################################################\n",
    "\n",
    "cat_cols = X_train.columns[X_train.dtypes == 'O'] # Returns array with the columns that has Object types elements\n",
    "\n",
    "\n",
    "categories = [\n",
    "    X_train[column].unique() for column in X_train[cat_cols]]\n",
    "\n",
    "for cat in categories:\n",
    "    cat[cat == None] = 'missing'  # noqa\n",
    "\n",
    "# Replacing missing values\n",
    "categorical_imputer = SimpleImputer(missing_values=None, \n",
    "                                    strategy='constant', \n",
    "                                    fill_value='missing')\n",
    "\n",
    "X_train[cat_cols] = categorical_imputer.fit_transform(X_train[cat_cols])\n",
    "\n",
    "# Encoding the categorical data\n",
    "categorical_encoder = OrdinalEncoder(categories = categories)\n",
    "\n",
    "X_train[cat_cols] = categorical_encoder.fit_transform(X_train[cat_cols])\n",
    "\n",
    "# Scaling new numerical values\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy = \"mean\")\n",
    "X_train[cat_cols] = numerical_imputer.fit_transform(X_train[cat_cols])\n",
    "\n",
    "numerical_scaler = StandardScaler()\n",
    "X_train[cat_cols] = numerical_scaler.fit_transform(X_train[cat_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Treat numerical data on train set\n",
    "####################################################################\n",
    "\n",
    "num_cols = X_train.columns[(X_train.dtypes == 'float64') | (X_train.dtypes == 'int64')] # Returns array with the columns that has float types elements\n",
    "\n",
    "# Scaling numerical values\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy = \"mean\")\n",
    "X_train[num_cols] = numerical_imputer.fit_transform(X_train[num_cols])\n",
    "\n",
    "numerical_scaler = StandardScaler()\n",
    "X_train[num_cols] = numerical_scaler.fit_transform(X_train[num_cols])\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Treat categorical data on test set (avoid leakeage)\n",
    "####################################################################\n",
    "\n",
    "cat_cols = X_test.columns[X_test.dtypes == 'O'] # Returns array with the columns that has Object types elements\n",
    "\n",
    "categories = [\n",
    "    X_test[column].unique() for column in X_test[cat_cols]]\n",
    "\n",
    "for cat in categories:\n",
    "    cat[cat == None] = 'missing'  # noqa\n",
    "\n",
    "\n",
    "# Replacing missing values\n",
    "categorical_imputer = SimpleImputer(missing_values=None, \n",
    "                                    strategy='constant', \n",
    "                                    fill_value='missing')\n",
    "\n",
    "X_test[cat_cols] = categorical_imputer.fit_transform(X_test[cat_cols])\n",
    "\n",
    "# Encoding the categorical data\n",
    "categorical_encoder = OrdinalEncoder(categories = categories)\n",
    "\n",
    "X_test[cat_cols] = categorical_encoder.fit_transform(X_test[cat_cols])\n",
    "\n",
    "# Scaling new numerical values\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy = \"mean\")\n",
    "X_test[cat_cols] = numerical_imputer.fit_transform(X_test[cat_cols])\n",
    "\n",
    "numerical_scaler = StandardScaler()\n",
    "X_test[cat_cols] = numerical_scaler.fit_transform(X_test[cat_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Treat numerical data on test set (avoid leakeage)\n",
    "####################################################################\n",
    "\n",
    "num_cols = X_test.columns[(X_test.dtypes == 'float64') | (X_test.dtypes == 'int64')] # Returns array with the columns that has float types elements\n",
    "\n",
    "# Scaling numerical values\n",
    "\n",
    "numerical_imputer = SimpleImputer(strategy = \"mean\")\n",
    "X_test[num_cols] = numerical_imputer.fit_transform(X_test[num_cols])\n",
    "\n",
    "numerical_scaler = StandardScaler()\n",
    "X_test[num_cols] = numerical_scaler.fit_transform(X_test[num_cols])\n",
    "\n",
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Training the model without cross-validation (simpler than the training above)\n",
    "###############################################################################\n",
    "\n",
    "# scikit-learn uses an optimised version of the CART algorithm;\n",
    "# however, scikit-learn implementation does not support categorical variables for now\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "import time\n",
    "\n",
    "# Assign the model to be used\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Making a Grid Search, with validation\n",
    "###############################################################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "criterion = {'criterion' : ['gini', 'entropy']}\n",
    "splitter = {'splitter' : ['best', 'random']}\n",
    "max_depth = {'max_depth' : [1, 10, 100, 1000, 10000, 100000, 1000000, None]}\n",
    "min_samples_split = {'min_samples_split' : [2, 3, 4]}\n",
    "\n",
    "grid_tree = GridSearchCV(clf, param_grid = [criterion, splitter, max_depth, min_samples_split] ,scoring = 'f1')\n",
    "grid_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Predict values based on new parameters\n",
    "y_pred = grid_tree.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.9706303891190567\n",
      "Precision Score : 0.9608578292901451\n",
      "Recall Score : 0.9809832321513884\n",
      "F1 Score : 0.9708162400431284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[332358,  13718],\n",
       "       [  6528, 336748]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Obtain metrics from the model above\n",
    "###############################################################################\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# New Model Evaluation metrics \n",
    "print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "print('F1 Score : ' + str(f1_score(y_test,y_pred)))\n",
    "\n",
    "#Logistic Regression (Grid Search) Confusion matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_split</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.241971</td>\n",
       "      <td>0.436961</td>\n",
       "      <td>0.266072</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>gini</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'criterion': 'gini'}</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.748953</td>\n",
       "      <td>0.172179</td>\n",
       "      <td>0.257833</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>entropy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'criterion': 'entropy'}</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.156780</td>\n",
       "      <td>0.491950</td>\n",
       "      <td>0.266278</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>best</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'splitter': 'best'}</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.143193</td>\n",
       "      <td>0.766571</td>\n",
       "      <td>0.281567</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'splitter': 'random'}</td>\n",
       "      <td>0.999929</td>\n",
       "      <td>0.999934</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.397965</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>0.249059</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>0.941960</td>\n",
       "      <td>0.949183</td>\n",
       "      <td>0.948545</td>\n",
       "      <td>0.948369</td>\n",
       "      <td>0.948529</td>\n",
       "      <td>0.947317</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.718848</td>\n",
       "      <td>0.127308</td>\n",
       "      <td>0.260905</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>0.999363</td>\n",
       "      <td>0.999618</td>\n",
       "      <td>0.999538</td>\n",
       "      <td>0.999612</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.999535</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.197051</td>\n",
       "      <td>0.520254</td>\n",
       "      <td>0.263737</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 100}</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.315241</td>\n",
       "      <td>0.408065</td>\n",
       "      <td>0.265260</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1000}</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.185185</td>\n",
       "      <td>0.498419</td>\n",
       "      <td>0.264005</td>\n",
       "      <td>0.003682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 10000}</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.221659</td>\n",
       "      <td>0.474455</td>\n",
       "      <td>0.264677</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 100000}</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.150312</td>\n",
       "      <td>0.516707</td>\n",
       "      <td>0.265208</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': 1000000}</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.242238</td>\n",
       "      <td>0.495307</td>\n",
       "      <td>0.266531</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'max_depth': None}</td>\n",
       "      <td>0.999947</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.209420</td>\n",
       "      <td>0.480999</td>\n",
       "      <td>0.268112</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>{'min_samples_split': 2}</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.318011</td>\n",
       "      <td>0.517185</td>\n",
       "      <td>0.268691</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>{'min_samples_split': 3}</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.266271</td>\n",
       "      <td>0.437931</td>\n",
       "      <td>0.267471</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>{'min_samples_split': 4}</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999965</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       11.241971      0.436961         0.266072        0.001977   \n",
       "1        7.748953      0.172179         0.257833        0.002143   \n",
       "2       11.156780      0.491950         0.266278        0.003591   \n",
       "3        4.143193      0.766571         0.281567        0.005675   \n",
       "4        1.397965      0.010667         0.249059        0.002376   \n",
       "5        8.718848      0.127308         0.260905        0.003885   \n",
       "6       11.197051      0.520254         0.263737        0.003063   \n",
       "7       11.315241      0.408065         0.265260        0.002898   \n",
       "8       11.185185      0.498419         0.264005        0.003682   \n",
       "9       11.221659      0.474455         0.264677        0.003201   \n",
       "10      11.150312      0.516707         0.265208        0.003001   \n",
       "11      11.242238      0.495307         0.266531        0.003272   \n",
       "12      11.209420      0.480999         0.268112        0.002532   \n",
       "13      11.318011      0.517185         0.268691        0.002287   \n",
       "14      11.266271      0.437931         0.267471        0.001861   \n",
       "\n",
       "   param_criterion param_splitter param_max_depth param_min_samples_split  \\\n",
       "0             gini            NaN             NaN                     NaN   \n",
       "1          entropy            NaN             NaN                     NaN   \n",
       "2              NaN           best             NaN                     NaN   \n",
       "3              NaN         random             NaN                     NaN   \n",
       "4              NaN            NaN               1                     NaN   \n",
       "5              NaN            NaN              10                     NaN   \n",
       "6              NaN            NaN             100                     NaN   \n",
       "7              NaN            NaN            1000                     NaN   \n",
       "8              NaN            NaN           10000                     NaN   \n",
       "9              NaN            NaN          100000                     NaN   \n",
       "10             NaN            NaN         1000000                     NaN   \n",
       "11             NaN            NaN            None                     NaN   \n",
       "12             NaN            NaN             NaN                       2   \n",
       "13             NaN            NaN             NaN                       3   \n",
       "14             NaN            NaN             NaN                       4   \n",
       "\n",
       "                      params  split0_test_score  split1_test_score  \\\n",
       "0      {'criterion': 'gini'}           0.999958           0.999973   \n",
       "1   {'criterion': 'entropy'}           0.999949           0.999978   \n",
       "2       {'splitter': 'best'}           0.999949           0.999967   \n",
       "3     {'splitter': 'random'}           0.999929           0.999934   \n",
       "4           {'max_depth': 1}           0.941960           0.949183   \n",
       "5          {'max_depth': 10}           0.999363           0.999618   \n",
       "6         {'max_depth': 100}           0.999947           0.999967   \n",
       "7        {'max_depth': 1000}           0.999947           0.999969   \n",
       "8       {'max_depth': 10000}           0.999945           0.999971   \n",
       "9      {'max_depth': 100000}           0.999951           0.999975   \n",
       "10    {'max_depth': 1000000}           0.999949           0.999967   \n",
       "11       {'max_depth': None}           0.999947           0.999971   \n",
       "12  {'min_samples_split': 2}           0.999955           0.999971   \n",
       "13  {'min_samples_split': 3}           0.999945           0.999967   \n",
       "14  {'min_samples_split': 4}           0.999940           0.999967   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0            0.999965           0.999971           0.999960         0.999965   \n",
       "1            0.999973           0.999976           0.999962         0.999968   \n",
       "2            0.999965           0.999967           0.999958         0.999961   \n",
       "3            0.999936           0.999962           0.999936         0.999940   \n",
       "4            0.948545           0.948369           0.948529         0.947317   \n",
       "5            0.999538           0.999612           0.999543         0.999535   \n",
       "6            0.999967           0.999962           0.999956         0.999960   \n",
       "7            0.999969           0.999969           0.999960         0.999963   \n",
       "8            0.999967           0.999969           0.999964         0.999963   \n",
       "9            0.999971           0.999967           0.999960         0.999965   \n",
       "10           0.999967           0.999971           0.999967         0.999964   \n",
       "11           0.999962           0.999960           0.999956         0.999959   \n",
       "12           0.999964           0.999960           0.999962         0.999962   \n",
       "13           0.999958           0.999971           0.999958         0.999960   \n",
       "14           0.999965           0.999967           0.999962         0.999960   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.000006                2  \n",
       "1         0.000011                1  \n",
       "2         0.000007                8  \n",
       "3         0.000011               13  \n",
       "4         0.002693               15  \n",
       "5         0.000092               14  \n",
       "6         0.000008               10  \n",
       "7         0.000009                6  \n",
       "8         0.000009                5  \n",
       "9         0.000008                3  \n",
       "10        0.000008                4  \n",
       "11        0.000008               12  \n",
       "12        0.000005                7  \n",
       "13        0.000009               11  \n",
       "14        0.000010                9  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_tree.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 9.776983976364136 seconds ---\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Train the model with adjusted parameters\n",
    "###############################################################################\n",
    "\n",
    "# Measure time of this training\n",
    "start_time = time.time()\n",
    "\n",
    "# Assign the model to be used with adjusted parameters\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Training the model\n",
    "model = clf.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.8136029659264673\n",
      "Recall Score:  0.9857869469464804\n",
      "Accuracy:  0.8804587496663533\n",
      "F1 Score:  0.8914567966280295\n",
      "[[[338397   4879]\n",
      "  [ 77527 268549]]\n",
      "\n",
      " [[268549  77527]\n",
      "  [  4879 338397]]]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Obtain metrics from the trained model without cross-validation\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Predicting from the test slice\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Precision == TP / (TP + FP)\n",
    "print('Precision Score: ', precision_score(y_test, y_pred))\n",
    "\n",
    "# Recall == TP / (TP + FN)\n",
    "print('Recall Score: ', recall_score(y_test, y_pred))\n",
    "\n",
    "# Accuracy \n",
    "train_score = model.score(X_test, y_test)\n",
    "print('Accuracy: ', train_score)\n",
    "\n",
    "# f1 \n",
    "f_one_score = f1_score(y_test, y_pred)\n",
    "print('F1 Score: ', f_one_score)\n",
    "\n",
    "# Multilabel Confusion Matrix: \n",
    "# [tn fp]\n",
    "# [fn tp]\n",
    "print(multilabel_confusion_matrix(y_test, y_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Plotting confusion matrix\n",
    "###############################################################################\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test)  # doctest: +SKIP\n",
    "plt.savefig(\"decision_tree_confusion_matrix.png\", format=\"png\")\n",
    "plt.show()  # doctest: +SKIP\n",
    "# td  sp  dp  pr  flg  ipkt ibyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
