{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Ernesto Rodr√≠guez\n",
    "# github.com/ernestorodg\n",
    "\n",
    "###############################################################################\n",
    "## Analyse Bezerra's dataset for intrusion detection using Decision Trees\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "###############################################################################\n",
    "## Define constants \n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Random state for reproducibility\n",
    "STATE = 0\n",
    "np.random.seed(10)\n",
    "# List of available attacks on the dataset\n",
    "\n",
    "\n",
    "# Especific to the repository \n",
    "DATASET_DIRECTORY = r'../datasets/Dataset-bezerra-IoT-20200528T203526Z-001/Dataset-IoT/'\n",
    "NETFLOW_DIRECTORY = r'NetFlow/'\n",
    "\n",
    "\n",
    "# There are different csv files on the Dataset, with different types of data:\n",
    "\n",
    "# Some meanings:\n",
    "# MC: Media Center\n",
    "# I: One hour of legitimate and malicious NetFlow data from profile.\n",
    "# L: One hour of legitimate NetFlow data from profile.\n",
    "\n",
    "MC = r'MC/'\n",
    "ST = r'ST/'\n",
    "SC = r'SC/'\n",
    "\n",
    "\n",
    "# MC_I_FIRST: Has infected data by Hajime, Aidra and BashLite botnets \n",
    "MC_I_FIRST = r'MC_I1.csv'\n",
    "\n",
    "# MC_I_SECOND: Has infected data from Mirai botnets\n",
    "MC_I_SECOND = r'MC_I2.csv'\n",
    "\n",
    "# MC_I_THIR: Has infected data from Mirai, Doflo, Tsunami and Wroba botnets\n",
    "MC_I_THIRD = r'MC_I3.csv'\n",
    "\n",
    "# MC_L: Has legitimate data, no infection\n",
    "MC_L = r'MC_L.csv'\n",
    "\n",
    "\n",
    "# Constants for ST\n",
    "ST_I_FIRST = r'ST_I1.csv'\n",
    "ST_I_SECOND = r'ST_I2.csv'\n",
    "ST_I_THIRD = r'ST_I3.csv'\n",
    "ST_L = r'ST_L.csv'\n",
    "\n",
    "# Constants for SC\n",
    "SC_I_FIRST = r'SC_I1.csv'\n",
    "SC_I_SECOND = r'SC_I2.csv'\n",
    "SC_I_THIRD = r'SC_I3.csv'\n",
    "SC_L = r'SC_L.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Load dataset\n",
    "###############################################################################\n",
    "\n",
    "# For MC data:\n",
    "df_mc_I_first = pd.read_csv (DATASET_DIRECTORY + MC + NETFLOW_DIRECTORY + MC_I_FIRST)\n",
    "df_mc_I_second = pd.read_csv (DATASET_DIRECTORY + MC + NETFLOW_DIRECTORY + MC_I_SECOND)\n",
    "df_mc_I_third = pd.read_csv (DATASET_DIRECTORY + MC + NETFLOW_DIRECTORY + MC_I_THIRD)\n",
    "\n",
    "# Add legitimate rows from MC_L\n",
    "legitimate_frame_mc = pd.read_csv (DATASET_DIRECTORY + MC + NETFLOW_DIRECTORY + MC_L)\n",
    "\n",
    "###################\n",
    "\n",
    "# For ST data:\n",
    "df_st_I_first = pd.read_csv (DATASET_DIRECTORY + ST + NETFLOW_DIRECTORY + ST_I_FIRST)\n",
    "df_st_I_second = pd.read_csv (DATASET_DIRECTORY + ST + NETFLOW_DIRECTORY + ST_I_SECOND)\n",
    "df_st_I_third = pd.read_csv (DATASET_DIRECTORY + ST + NETFLOW_DIRECTORY + ST_I_THIRD)\n",
    "\n",
    "# Add legitimate rows from SC_L\n",
    "legitimate_frame_st = pd.read_csv (DATASET_DIRECTORY + ST + NETFLOW_DIRECTORY + ST_L)\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "# For SC data:\n",
    "df_sc_I_first = pd.read_csv (DATASET_DIRECTORY + SC + NETFLOW_DIRECTORY + SC_I_FIRST)\n",
    "df_sc_I_second = pd.read_csv (DATASET_DIRECTORY + SC + NETFLOW_DIRECTORY + SC_I_SECOND)\n",
    "df_sc_I_third = pd.read_csv (DATASET_DIRECTORY + SC + NETFLOW_DIRECTORY + SC_I_THIRD)\n",
    "\n",
    "# Add legitimate rows from MC_L\n",
    "legitimate_frame_sc = pd.read_csv (DATASET_DIRECTORY + SC + NETFLOW_DIRECTORY + SC_L)\n",
    "\n",
    "dataframes_list = [df_mc_I_first,\n",
    "                df_mc_I_second,\n",
    "                df_mc_I_third,\n",
    "                legitimate_frame_mc,\n",
    "                df_st_I_first,\n",
    "                df_st_I_second,\n",
    "                df_st_I_third,\n",
    "                legitimate_frame_st,\n",
    "                df_sc_I_first,\n",
    "                df_sc_I_second,\n",
    "                df_sc_I_third,\n",
    "                legitimate_frame_sc]\n",
    "\n",
    "# Joining the differents DataFrames\n",
    "prev_df = pd.concat(dataframes_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Modify the DataFrame\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "# Sample the dataset if necessary\n",
    "df = prev_df.sample (frac = 1, replace = True, random_state = 0)\n",
    "\n",
    "# We can see that this dataset has a temporal description.\n",
    "# So it is not a good idea to randomly remove rows\n",
    "\n",
    "# In this case we drop the index column, since pandas library creates an index\n",
    "# automatically. \n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "\n",
    "# Also drop columns that has no significant data\n",
    "df = df.drop(df.columns[14:], axis=1)\n",
    "\n",
    "# Initial and end time is not a good feature for svm model\n",
    "df = df.drop(['ts', 'te'], axis=1)\n",
    "\n",
    "# Trying another drops to see relation between features and results\n",
    "df = df.drop(['fwd', 'stos'], axis=1)\n",
    "# 'sp', 'dp', 'sa',  'da',  \n",
    "\n",
    "# Counting number of null data\n",
    "nanColumns = [i for i in df.columns if df [i].isnull ().any ()]\n",
    "\n",
    "# Remove NaN and inf values\n",
    "df.replace ('Infinity', np.nan, inplace = True) ## Or other text values\n",
    "df.replace (np.inf, np.nan, inplace = True) ## Remove infinity\n",
    "df.replace (np.nan, 0, inplace = True)\n",
    "\n",
    "\n",
    "# if (df.Label.value_counts()[1] < df.Label.value_counts()[0]):\n",
    "#     remove_n =  df.Label.value_counts()[0] - df.Label.value_counts()[1]  # Number of rows to be removed   \n",
    "#     print(remove_n)\n",
    "#     df_to_be_dropped = df[df.Label == 0]\n",
    "#     drop_indices = np.random.choice(df_to_be_dropped.index, remove_n, replace=False)\n",
    "#     df = df.drop(drop_indices)\n",
    "# else: \n",
    "#     remove_n =  df.Label.value_counts()[1] - df.Label.value_counts()[0]  # Number of rows to be removed   \n",
    "#     print(remove_n)\n",
    "#     df_to_be_dropped = df[df.Label == 1]\n",
    "#     drop_indices = np.random.choice(df_to_be_dropped.index, remove_n, replace=False)\n",
    "#     df = df.drop(drop_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-attacks:  7998\n",
      "Number of attacks:  1716408\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Slice the dataframe (usually the last column is the target)\n",
    "###############################################################################\n",
    "\n",
    "X = pd.DataFrame(df.iloc [:, 1:])\n",
    "\n",
    "# Selecting other columns\n",
    "# X = pd.concat([X, df.iloc[:, 2]], axis=1)\n",
    "\n",
    "y = df.iloc [:, 0]\n",
    "print('Number of non-attacks: ', y.value_counts()[0])\n",
    "print('Number of attacks: ', y.value_counts()[1])\n",
    "\n",
    "# See Output, only available on jupyter-notebooks\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-attacks:  1716408\n",
      "Number of attacks:  1716408\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Create artificial non-attacks samples using Random Oversampling\n",
    "###############################################################################\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "print('Number of non-attacks: ', y.value_counts()[0])\n",
    "print('Number of attacks: ', y.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2746252, 9)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Split dataset into train and test sets if not using cross validation\n",
    "###############################################################################\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 1/5,\n",
    "                                                     random_state = STATE)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(686564, 9)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Treat categorical data on train set\n",
    "####################################################################\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "cat_cols = X_train.columns[X_train.dtypes == 'O'] # Returns array with the columns that has Object types elements\n",
    "\n",
    "categories = [\n",
    "    X_train[column].unique() for column in X_train[cat_cols]]\n",
    "\n",
    "for cat in categories:\n",
    "    cat[cat == None] = 'missing'  # noqa\n",
    "\n",
    "# Replacing missing values\n",
    "categorical_imputer = SimpleImputer(missing_values=None, \n",
    "                                    strategy='constant', \n",
    "                                    fill_value='missing')\n",
    "\n",
    "X_train[cat_cols] = categorical_imputer.fit_transform(X_train[cat_cols])\n",
    "\n",
    "# Encoding the categorical data\n",
    "categorical_encoder = OrdinalEncoder(categories = categories)\n",
    "categorical_encoder.fit(X_train[cat_cols])\n",
    "X_train[cat_cols] = categorical_encoder.transform(X_train[cat_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Treat categorical data on test set\n",
    "####################################################################\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "cat_cols = X_test.columns[X_test.dtypes == 'O'] # Returns array with the columns that has Object types elements\n",
    "\n",
    "categories = [\n",
    "    X_test[column].unique() for column in X_test[cat_cols]]\n",
    "\n",
    "for cat in categories:\n",
    "    cat[cat == None] = 'missing'  # noqa\n",
    "\n",
    "# Replacing missing values\n",
    "categorical_imputer = SimpleImputer(missing_values=None, \n",
    "                                    strategy='constant', \n",
    "                                    fill_value='missing')\n",
    "\n",
    "X_test[cat_cols] = categorical_imputer.fit_transform(X_test[cat_cols])\n",
    "\n",
    "# Encoding the categorical data\n",
    "categorical_encoder = OrdinalEncoder(categories = categories)\n",
    "categorical_encoder.fit(X_test[cat_cols])\n",
    "X_test[cat_cols] = categorical_encoder.transform(X_test[cat_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>td</th>\n",
       "      <th>sa</th>\n",
       "      <th>da</th>\n",
       "      <th>sp</th>\n",
       "      <th>dp</th>\n",
       "      <th>pr</th>\n",
       "      <th>flg</th>\n",
       "      <th>ipkt</th>\n",
       "      <th>ibyt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40758</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694353</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64205</td>\n",
       "      <td>10505.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001901</th>\n",
       "      <td>122821.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>443</td>\n",
       "      <td>54416.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10976.0</td>\n",
       "      <td>16429973.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720671</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46412</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206690</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45130</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597178</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276171.0</td>\n",
       "      <td>10688</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3304576</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>53705</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722033</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276172.0</td>\n",
       "      <td>51491</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276173.0</td>\n",
       "      <td>39907</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>276174.0</td>\n",
       "      <td>31916</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686564 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               td   sa        da     sp       dp   pr  flg     ipkt  \\\n",
       "104004        0.0  0.0       0.0  40758     23.0  0.0  0.0      1.0   \n",
       "2694353       0.0  1.0       1.0  64205  10505.0  1.0  1.0      1.0   \n",
       "3001901  122821.0  2.0       2.0    443  54416.0  0.0  2.0  10976.0   \n",
       "720671        0.0  0.0       3.0  46412     81.0  0.0  0.0      1.0   \n",
       "206690        0.0  0.0       4.0  45130     23.0  0.0  0.0      1.0   \n",
       "...           ...  ...       ...    ...      ...  ...  ...      ...   \n",
       "597178        0.0  0.0  276171.0  10688     23.0  0.0  0.0      1.0   \n",
       "3304576      71.0  0.0       7.0  53705     53.0  1.0  1.0      1.0   \n",
       "722033        0.0  0.0  276172.0  51491     23.0  0.0  0.0      1.0   \n",
       "1280184       0.0  0.0  276173.0  39907     23.0  0.0  0.0      1.0   \n",
       "536340        0.0  0.0  276174.0  31916     23.0  0.0  0.0      1.0   \n",
       "\n",
       "               ibyt  \n",
       "104004         40.0  \n",
       "2694353       125.0  \n",
       "3001901  16429973.0  \n",
       "720671         40.0  \n",
       "206690         40.0  \n",
       "...             ...  \n",
       "597178         40.0  \n",
       "3304576        59.0  \n",
       "722033         40.0  \n",
       "1280184        40.0  \n",
       "536340         40.0  \n",
       "\n",
       "[686564 rows x 9 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################################################\n",
    "# # Treat categorical data on train set\n",
    "# ####################################################################\n",
    "\n",
    "# cat_cols = X_train.columns[X_train.dtypes == 'O'] # Returns array with the columns that has Object types elements\n",
    "\n",
    "\n",
    "# categories = [\n",
    "#     X_train[column].unique() for column in X_train[cat_cols]]\n",
    "\n",
    "# for cat in categories:\n",
    "#     cat[cat == None] = 'missing'  # noqa\n",
    "\n",
    "# # Replacing missing values\n",
    "# categorical_imputer = SimpleImputer(missing_values=None, \n",
    "#                                     strategy='constant', \n",
    "#                                     fill_value='missing')\n",
    "\n",
    "# X_train[cat_cols] = categorical_imputer.fit_transform(X_train[cat_cols])\n",
    "\n",
    "# # Encoding the categorical data\n",
    "# categorical_encoder = OrdinalEncoder(categories = categories)\n",
    "\n",
    "# X_train[cat_cols] = categorical_encoder.fit_transform(X_train[cat_cols])\n",
    "\n",
    "# # Scaling new numerical values\n",
    "\n",
    "# numerical_imputer = SimpleImputer(strategy = \"mean\")\n",
    "# X_train[cat_cols] = numerical_imputer.fit_transform(X_train[cat_cols])\n",
    "\n",
    "# numerical_scaler = StandardScaler()\n",
    "# X_train[cat_cols] = numerical_scaler.fit_transform(X_train[cat_cols])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Treat numerical data \n",
    "####################################################################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "num_cols = X_train.columns[(X_train.dtypes == 'float64') | (X_train.dtypes == 'int64')] # Returns array with the columns that has float types elements\n",
    "\n",
    "# Scaling numerical values\n",
    "\n",
    "numerical_scaler = StandardScaler()\n",
    "numerical_scaler.fit(X_train)\n",
    "X_train = numerical_scaler.transform(X_train)\n",
    "\n",
    "X_test = numerical_scaler.transform(X_test)\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.15770152, -0.16205196, -0.68835123, ..., -0.70083444,\n",
       "        -0.09456574, -0.07384662],\n",
       "       [-0.15770152, -0.16185528, -0.68834715, ..., -0.26596623,\n",
       "        -0.09456574, -0.07383219],\n",
       "       [ 0.33105289, -0.1616586 , -0.68834306, ...,  0.16890198,\n",
       "         2.43265334,  2.71553972],\n",
       "       ...,\n",
       "       [-0.15770152, -0.16205196,  0.43882876, ..., -0.70083444,\n",
       "        -0.09456574, -0.07384662],\n",
       "       [-0.15770152, -0.16205196,  0.43883284, ..., -0.70083444,\n",
       "        -0.09456574, -0.07384662],\n",
       "       [-0.15770152, -0.16205196,  0.43883692, ..., -0.70083444,\n",
       "        -0.09456574, -0.07384662]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2746252, 9)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ###############################################################################\n",
    "# ## Apply normalization\n",
    "# ###############################################################################\n",
    "\n",
    "# print ('Applying normalization (standard)')\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler ()\n",
    "# scaler.fit (X_train)\n",
    "\n",
    "# #print ('Mean before scalling:', scaler.mean_)\n",
    "# X_train = scaler.transform (X_train)\n",
    "# scaler.fit (X_train)\n",
    "# #print ('Mean after scalling:', scaler.mean_)\n",
    "\n",
    "# scaler.fit (X_test)\n",
    "# X_test = scaler.transform (X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "## Training the model without cross-validation (simpler than the training above)\n",
    "###############################################################################\n",
    "\n",
    "# scikit-learn uses an optimised version of the CART algorithm;\n",
    "# however, scikit-learn implementation does not support categorical variables for now\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "import time\n",
    "\n",
    "# Assign the model to be used\n",
    "clf = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(686564, 9)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################\n",
    "# ## Making a Grid Search, with validation\n",
    "# ###############################################################################\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# criterion = {'criterion' : ['gini', 'entropy']}\n",
    "# splitter = {'splitter' : ['best', 'random']}\n",
    "# max_depth = {'max_depth' : [1, 10, 100, 1000, 10000, 100000, 1000000, None]}\n",
    "# min_samples_split = {'min_samples_split' : [2, 3, 4]}\n",
    "\n",
    "# grid_tree = GridSearchCV(clf, param_grid = [criterion, splitter, max_depth, min_samples_split] ,scoring = 'f1')\n",
    "# grid_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# #Predict values based on new parameters\n",
    "# y_pred = grid_tree.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###############################################################################\n",
    "# ## Obtain metrics from the model above\n",
    "# ###############################################################################\n",
    "\n",
    "# from sklearn.metrics import precision_score\n",
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import multilabel_confusion_matrix\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# # New Model Evaluation metrics \n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test,y_pred)))\n",
    "# print('Precision Score : ' + str(precision_score(y_test,y_pred)))\n",
    "# print('Recall Score : ' + str(recall_score(y_test,y_pred)))\n",
    "# print('F1 Score : ' + str(f1_score(y_test,y_pred)))\n",
    "\n",
    "# #Logistic Regression (Grid Search) Confusion matrix\n",
    "# confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 20.369957447052002 seconds ---\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Train the model with adjusted parameters\n",
    "###############################################################################\n",
    "\n",
    "# Measure time of this training\n",
    "start_time = time.time()\n",
    "\n",
    "# Assign the model to be used with adjusted parameters\n",
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "\n",
    "# Training the model\n",
    "model = clf.fit(X_train, y_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:  0.9871107821935283\n",
      "Recall Score:  0.9995363755649511\n",
      "Accuracy:  0.9932489906257829\n",
      "F1 Score:  0.9932847206023613\n",
      "[[[342791    159]\n",
      "  [  4476 339138]]\n",
      "\n",
      " [[339138   4476]\n",
      "  [   159 342791]]]\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Obtain metrics from the trained model without cross-validation\n",
    "###############################################################################\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Predicting from the test slice\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Precision == TP / (TP + FP)\n",
    "print('Precision Score: ', precision_score(y_test, y_pred))\n",
    "\n",
    "# Recall == TP / (TP + FN)\n",
    "print('Recall Score: ', recall_score(y_test, y_pred))\n",
    "\n",
    "# Accuracy \n",
    "train_score = model.score(X_test, y_test)\n",
    "print('Accuracy: ', train_score)\n",
    "\n",
    "# f1 \n",
    "f_one_score = f1_score(y_test, y_pred)\n",
    "print('F1 Score: ', f_one_score)\n",
    "\n",
    "# Multilabel Confusion Matrix: \n",
    "# [tn fp]\n",
    "# [fn tp]\n",
    "print(multilabel_confusion_matrix(y_test, y_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################################################################\n",
    "## Plotting confusion matrix\n",
    "###############################################################################\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plot_confusion_matrix(model, X_test, y_test)  # doctest: +SKIP\n",
    "plt.savefig(\"decision_tree_confusion_matrix.png\", format=\"png\")\n",
    "plt.show()  # doctest: +SKIP\n",
    "# td  sp  dp  pr  flg  ipkt ibyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
